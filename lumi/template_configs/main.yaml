defaults:
- data: zarr
- dataloader: native_grid
- diagnostics: evaluation
- hardware: example
- graph: multi_scale
- model: graphtransformer
- training: default
- override hydra/hydra_logging: disabled
- override hydra/job_logging: disabled
- _self_

hydra:  
  output_subdir: null  
  run:  
    dir: .

dataloader:
  num_workers:
    training: 2
    validation: 2
    test: 2
    predict: 2
  batch_size:
    training: 1
    validation: 1
    test: 1
    predict: 1

  dataset:
    dataset:
      join:
        - ${hardware.paths.data}/${hardware.files.dataset_1}
        - ${hardware.paths.data}/${hardware.files.dataset_2}
      adjust: [dates]
    #trimedge branch
    mask_from_dataset:
      dataset: /pfs/lustrep3/scratch/project_465002266/datasets/mask_norkyst_2024.zarr
      field: land_binary_mask_0

  limit_batches: 
    training: null
    validation: null
    test: null
    predict: null

  training:
    start: 2024-01-01
    end: 2024-01-31
    #select: ['salinity_1', 'temperature_1', 'u_eastward_1', 'v_northward_1', 'w_1', 'zeta']
    dataset: ${dataloader.dataset} 
    frequency: 1
  validation:
    start: 2024-02-01
    end: 2024-02-28
    #select: ['salinity_1', 'temperature_1', 'u_eastward_1', 'v_northward_1', 'w_1', 'zeta']
    dataset: ${dataloader.dataset}
    frequency: 1
  test:
    start: 2024-03-01
    end: 2024-03-31
    #select: ['salinity_1', 'temperature_1', 'u_eastward_1', 'v_northward_1', 'w_1', 'zeta']
    dataset: ${dataloader.dataset}
    frequency: 1

hardware:
  num_gpus_per_node: 8
  num_nodes: 1
  num_gpus_per_model: 4
  accelerator: auto
  paths:
    data: /pfs/lustrep3/scratch/project_465002266/datasets/
    output: /pfs/lustrep3/scratch/project_465002266/experiments/exp-name/
    graph: /pfs/lustrep3/scratch/project_465002266/graphs/
  files:
    dataset_1: prepro_norkyst_tests/norkyst800_his_zdepth_2024_m00_AN_ml.zarr
    dataset_2: h_norkyst_2024.zarr
    graph: graph-17-12-res7.pt
    warm_start: null #specific checkpoint to start from, defaults to last.ckpt

diagnostics:
  plot: 
    callbacks: []
  log:
    mlflow:
      enabled: True
      offline: True
      authentication: True
      tracking_uri: https://mlflow.ecmwf.int
      experiment_name: 'metno-fou'
      run_name: your_descriptive_run_name #change this
  print_memory_summary: True

# Set clobber: False and specify the correct path and file in hardware to load graph, the path below is 
# only used for saving graphs.
graph:
  overwrite: False
  nodes:
    data: 
      node_builder:
        _target_: anemoi.graphs.nodes.ZarrDatasetNodes # options: ZarrDatasetNodes, NPZFileNodes
        dataset: ${dataloader.training.dataset}
      attributes:
        area_weight:
          _target_: anemoi.graphs.nodes.attributes.UniformWeights
          norm: unit-max
    hidden:
      node_builder:
        _target_: anemoi.graphs.nodes.LimitedAreaTriNodes # options: ZarrDatasetNodes, NPZFileNodes, TriNodes
        resolution: 5 # grid resolution for npz (o32, o48, ...)
        reference_node_name: ${graph.data}

  #mulig dette kan fjernes
  edges:
    # Encoder configuration
    - source_name: ${graph.data}
      target_name: ${graph.hidden}
      edge_builders:
      - _target_: anemoi.graphs.edges.CutOffEdges # options: KNNEdges, CutOffEdges
        cutoff_factor: 0.6 # only for cutoff method
      attributes: ${graph.attributes.edges}
      # Processor configuration
    - source_name: ${graph.hidden}
      target_name: ${graph.hidden}
      edge_builders:
      - _target_: anemoi.graphs.edges.MultiScaleEdges
        x_hops: 1
      attributes: ${graph.attributes.edges}
      # Decoder configuration
    - source_name: ${graph.hidden}
      target_name: ${graph.data}
      edge_builders:
      - _target_: anemoi.graphs.edges.KNNEdges # options: KNNEdges, CutOffEdges
        num_nearest_neighbours: 3 # only for knn method
      attributes: ${graph.attributes.edges}

graphs:
  output_path: ${hardware.paths.graph}${hardware.files.graph}
  save_graph_plots: False
  clobber: False

data:
  resolution: o96
  frequency: 1h
  timestep: 1h
  format: zarr
  forcing: 
    - h
    - Uwind_eastward
    - Vwind_northward

  diagnostic: []

  remapped:

  normalizer:
    default: "mean-std"
    std: []

    min-max:
    max: []
    none: []

  imputer:
    #legge til flere variabler her når vi har det
    default: "none"
    999:
  #    - temperature_0 # ERROR if try to impute vars that dont have NaNs. Ok to list vars not in dataset (if use select)
      - temperature_15
      - temperature_25
      - temperature_50
      - temperature_65
      - temperature_75
      - temperature_100
      - temperature_200
      - temperature_300
      - salinity_15
      - salinity_25
      - salinity_50
      - salinity_65
      - salinity_75
      - salinity_100
      - salinity_200
      - salinity_300
      - u_eastward_15
      - u_eastward_25
      - u_eastward_50
      - u_eastward_65
      - u_eastward_75
      - u_eastward_100
      - u_eastward_200
      - u_eastward_300
      - v_northward_15
      - v_northward_25
      - v_northward_50
      - v_northward_65
      - v_northward_75
      - v_northward_100
      - v_northward_200
      - v_northward_300
      - w_15
      - w_25
      - w_50
      - w_65
      - w_75
      - w_100
      - w_200
      - w_300

  remapper:
    default: "none"

  processors:

    normalizer:
      _target_: anemoi.models.preprocessing.normalizer.InputNormalizer
      _convert_: all
      config: ${data.normalizer}
    
    imputer:
      _target_: anemoi.models.preprocessing.imputer.ConstantImputer
      _convert_: all
      config: ${data.imputer}

  # Values set in the code
  num_features: null # number of features in the forecast state


model:
  num_channels: 1024
  trainable_parameters:
    data: 0
    hidden: 0
    data2hidden: 0
    hidden2data: 0
    hidden2hidden: 0 # GNN and GraphTransformer Processor only
  bounding: #These are applied in order
    - _target_: anemoi.models.layers.bounding.ReluBounding #[0, infinity)
      variables: []

training:
  run_id: null #path to store the experiment in with output_base as root, null for random name, =fork_run_id to continue training in the same folder.
  fork_run_id: null #path to the experiment to fork from with output_base as root
  load_weights_only: False #loads entire model if False, loads only weights if True
  max_epochs: null
  max_steps: 150000
  lr:
    rate: 6.25e-5
    min: 3e-7
